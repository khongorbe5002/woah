{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e46054c1",
   "metadata": {},
   "source": [
    "# Export YOLOv10n to ONNX — Colab\n",
    "This notebook walks through exporting a YOLO `.pt` model to ONNX using a Colab environment (GPU recommended). Follow the cells in order: install dependencies, upload model, export (via helper script or direct API), validate ONNX, and download the result.\n",
    "\n",
    "**Select Runtime → Change runtime type → Hardware accelerator: GPU**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0005ab4",
   "metadata": {},
   "source": [
    "## Section 1 — Setup & Imports\n",
    "Install required packages and import standard libraries. Run the cell below to set up the Colab environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd65d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (run this cell)\n",
    "!pip install --upgrade pip\n",
    "!pip install ultralytics onnx onnxruntime onnxsim --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18b8d71",
   "metadata": {},
   "source": [
    "## Section 2 — Environment & dependency checks\n",
    "Verify Python version and that key packages are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4d6ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick environment checks\n",
    "import sys\n",
    "print('Python', sys.version)\n",
    "\n",
    "# show installed ultralytics if present\n",
    "!python -c \"import ultralytics; print('ultralytics', ultralytics.__version__)\" || echo 'ultralytics not installed'\n",
    "\n",
    "# List packages of interest\n",
    "!python -m pip show onnx onnxruntime onnxsim || true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d812675",
   "metadata": {},
   "source": [
    "## Section 3 — Upload/YAML & inspect model\n",
    "Upload a `.pt` model from your machine or download it via URL. The cell below uses `files.upload()` to let you select a file interactively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fdd27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload .pt model interactively\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "for fname in uploaded:\n",
    "    print('Uploaded:', fname)\n",
    "\n",
    "# Optionally check filesize and list\n",
    "import os\n",
    "for fname in uploaded:\n",
    "    print(fname, os.path.getsize(fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd3025b",
   "metadata": {},
   "source": [
    "## Sections 4-6 — Preprocessing, Features, EDA (Placeholders)\n",
    "These sections are included as a template for broader data workflows. For model export they are typically not required, but we keep short examples and placeholders to show how you'd document and test these steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3866ad9",
   "metadata": {},
   "source": [
    "## Section 7 — Export model to ONNX (helper script)\n",
    "Use the repo's helper export script to convert your uploaded `.pt` to `.onnx`.\n",
    "\n",
    "Run the cell below to run: `python scripts/export_yolo_to_onnx.py --model yolov10n.pt --output yolov10n.onnx --opset 12 --simplify` (replace filenames as needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c86b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the helper script (adjust arguments if your model has another name)\n",
    "!python scripts/export_yolo_to_onnx.py --model yolov10n.pt --output yolov10n.onnx --opset 12 --simplify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c349fe14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct export via ultralytics API (alternative)\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    print('ultralytics available:', YOLO)\n",
    "    model = YOLO('yolov10n.pt')\n",
    "    print('Exporting using ultralytics API...')\n",
    "    model.export(format='onnx', opset=12, imgsz=640, simplify=True)\n",
    "    print('API export finished.')\n",
    "except Exception as e:\n",
    "    print('Ultralytics API export failed:', e)\n",
    "    print('You can still try the helper script or adjust opset/simplify.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa74212",
   "metadata": {},
   "source": [
    "## Section 8 — Validate ONNX\n",
    "Check the exported ONNX file with `onnx.checker` and ensure `onnxruntime` can load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ae1bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONNX validation\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "\n",
    "onnx_path = 'yolov10n.onnx'\n",
    "try:\n",
    "    model = onnx.load(onnx_path)\n",
    "    onnx.checker.check_model(model)\n",
    "    print('ONNX check: OK')\n",
    "    sess = ort.InferenceSession(onnx_path)\n",
    "    print('onnxruntime providers:', sess.get_providers())\n",
    "except Exception as e:\n",
    "    print('ONNX validation failed:', e)\n",
    "    print('Check the export output and try different opset/simplify settings')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7417ef6",
   "metadata": {},
   "source": [
    "## Section 9 — Save & export artifacts\n",
    "Download the ONNX or copy it to your Google Drive for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c04d9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the ONNX file to your local machine\n",
    "from google.colab import files\n",
    "files.download('yolov10n.onnx')\n",
    "\n",
    "# OR: copy to Google Drive (uncomment to use)\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# !cp yolov10n.onnx /content/drive/MyDrive/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba3a3c0",
   "metadata": {},
   "source": [
    "## Section 10 — Unit tests & reproducibility\n",
    "Example: a short pytest test ensuring ONNX loads and that a basic forward pass runs (uses a random input for smoke test).\n",
    "\n",
    "```python\n",
    "# tests/test_onnx_load.py\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "\n",
    "\n",
    "def test_onnx_load_and_session():\n",
    "    model = onnx.load('yolov10n.onnx')\n",
    "    onnx.checker.check_model(model)\n",
    "    sess = ort.InferenceSession('yolov10n.onnx')\n",
    "    assert 'CPUExecutionProvider' in sess.get_providers()\n",
    "```\n",
    "\n",
    "Run tests with `pytest -q` after saving the file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a7cd94",
   "metadata": {},
   "source": [
    "## Section 11 — Running & debugging in VS Code\n",
    "- You can open this notebook in VS Code and run cells interactively.\n",
    "- Use the Jupyter extension or the built-in Notebook UI.\n",
    "- To debug cells in VS Code set breakpoints in the cell and use the 'Run by line' or the Debug Cell action.\n",
    "\n",
    "**Open in Colab**: you can upload this notebook to Colab or use `Open in Colab` links if you publish the repo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7397a6c",
   "metadata": {},
   "source": [
    "---\n",
    "## Troubleshooting & Tips\n",
    "- If export fails with errors from `torch` or `ultralytics`, run the export on an x86 machine or use Colab GPU runtime (this notebook).\n",
    "- Try opset 11/12 if you see unsupported operator errors.\n",
    "- If `onnx.checker` fails, try exporting without `simplify=True` to inspect raw errors.\n",
    "- Use `onnxruntime` CPU provider for quick checks; GPU provider requires additional setup.\n",
    "\n",
    "If you want, run the cells now. If you'd like, I can also add a short example to run inference with the ONNX model on a sample image inside this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c13ca8",
   "metadata": {},
   "source": [
    "## Optional: Run an ONNX inference example on a sample image\n",
    "Upload a sample image and run a small inference + visualization step to verify the exported ONNX works on a real image.\n",
    "\n",
    "Notes:\n",
    "- The ONNX output format may vary between model exports. The cell below attempts a robust parsing for common YOLO-style outputs (xywh + confidence + class scores). If your model uses a different layout, adapt the parsing accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15bcb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a sample image: prefer the repo-provided sample if available\n",
    "import os\n",
    "sample_b64 = 'data/sample_image.b64'\n",
    "sample_png = 'data/sample_image.png'\n",
    "\n",
    "if os.path.exists(sample_png):\n",
    "    img_path = sample_png\n",
    "    print('Using repo sample image:', img_path)\n",
    "elif os.path.exists(sample_b64):\n",
    "    print('Extracting sample image from base64...')\n",
    "    import subprocess\n",
    "    subprocess.run([\"python\", \"scripts/extract_sample_image.py\"], check=False)\n",
    "    if os.path.exists(sample_png):\n",
    "        img_path = sample_png\n",
    "        print('Extracted and using:', img_path)\n",
    "    else:\n",
    "        print('Extraction failed; falling back to upload prompt')\n",
    "        from google.colab import files\n",
    "        uploaded = files.upload()\n",
    "        if len(uploaded) == 0:\n",
    "            raise SystemExit('No image uploaded.')\n",
    "        img_path = next(iter(uploaded.keys()))\n",
    "        print('Using uploaded image:', img_path)\n",
    "else:\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "    if len(uploaded) == 0:\n",
    "        raise SystemExit('No image uploaded.')\n",
    "    img_path = next(iter(uploaded.keys()))\n",
    "    print('Using uploaded image:', img_path)\n",
    "\n",
    "# Show the image\n",
    "from PIL import Image\n",
    "Image.open(img_path).resize((400,400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb4ffcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ONNX inference and visualize detections\n",
    "import cv2\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load image\n",
    "img_bgr = cv2.imread(img_path)\n",
    "if img_bgr is None:\n",
    "    raise SystemExit('Failed to read image')\n",
    "img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "orig_h, orig_w = img_rgb.shape[:2]\n",
    "\n",
    "# Settings\n",
    "input_size = 640  # match the size used for export\n",
    "conf_thresh = 0.4\n",
    "\n",
    "# Preprocess: resize (no letterbox for simplicity) and normalize\n",
    "img_resized = cv2.resize(img_rgb, (input_size, input_size))\n",
    "input_tensor = img_resized.astype(np.float32) / 255.0\n",
    "input_tensor = np.transpose(input_tensor, (2, 0, 1))[None, :]\n",
    "\n",
    "# Run session\n",
    "sess = ort.InferenceSession('yolov10n.onnx')\n",
    "input_name = sess.get_inputs()[0].name\n",
    "outputs = sess.run(None, {input_name: input_tensor})\n",
    "print('Number of outputs:', len(outputs))\n",
    "for i, out in enumerate(outputs):\n",
    "    print(f'output[{i}] shape:', out.shape)\n",
    "\n",
    "# Try to parse the first output into detections (common YOLO layouts)\n",
    "out = outputs[0]\n",
    "if out.ndim == 3:  # (1, N, C)\n",
    "    dets = out[0]\n",
    "elif out.ndim == 2:  # (N, C)\n",
    "    dets = out\n",
    "else:\n",
    "    print('Unexpected ONNX output shape; raw output shown above. Inspect and adapt parsing.')\n",
    "    dets = None\n",
    "\n",
    "coco_names = [\n",
    "    'person','bicycle','car','motorcycle','airplane','bus','train','truck','boat','traffic light','fire hydrant','stop sign','parking meter','bench','bird','cat','dog','horse','sheep','cow','elephant','bear','zebra','giraffe','backpack','umbrella','handbag','tie','suitcase','frisbee','skis','snowboard','sports ball','kite','baseball bat','baseball glove','skateboard','surfboard','tennis racket','bottle','wine glass','cup','fork','knife','spoon','bowl','banana','apple','sandwich','orange','broccoli','carrot','hot dog','pizza','donut','cake','chair','couch','potted plant','bed','dining table','toilet','tv','laptop','mouse','remote','keyboard','cell phone','microwave','oven','toaster','sink','refrigerator','book','clock','vase','scissors','teddy bear','hair drier','toothbrush'\n",
    "]\n",
    "\n",
    "vis = img_rgb.copy()\n",
    "if dets is not None and dets.shape[1] >= 6:\n",
    "    # Interpret as: x_center, y_center, w, h, conf, class_scores... or x,y,w,h,conf,class_id\n",
    "    x = dets[:, 0]\n",
    "    y = dets[:, 1]\n",
    "    w = dets[:, 2]\n",
    "    h = dets[:, 3]\n",
    "    conf = dets[:, 4]\n",
    "\n",
    "    if dets.shape[1] > 6:\n",
    "        class_scores = dets[:, 5:]\n",
    "        class_idx = np.argmax(class_scores, axis=1)\n",
    "        class_score = np.max(class_scores, axis=1)\n",
    "        final_score = conf * class_score\n",
    "    else:\n",
    "        class_idx = dets[:, 5].astype(int)\n",
    "        final_score = conf\n",
    "\n",
    "    # If coordinates are normalized (<=1), convert to pixels in resized image\n",
    "    if np.max(w) <= 1.0 + 1e-6:\n",
    "        x *= input_size\n",
    "        y *= input_size\n",
    "        w *= input_size\n",
    "        h *= input_size\n",
    "\n",
    "    x1 = x - w / 2\n",
    "    y1 = y - h / 2\n",
    "    x2 = x + w / 2\n",
    "    y2 = y + h / 2\n",
    "\n",
    "    # Scale back to original image size\n",
    "    sx = orig_w / input_size\n",
    "    sy = orig_h / input_size\n",
    "    x1 *= sx; x2 *= sx; y1 *= sy; y2 *= sy\n",
    "\n",
    "    # Filter and draw\n",
    "    indices = np.where(final_score > conf_thresh)[0]\n",
    "    print(f'Filtered {len(indices)} detections (score > {conf_thresh})')\n",
    "    for i in indices:\n",
    "        xa, ya, xb, yb = int(x1[i]), int(y1[i]), int(x2[i]), int(y2[i])\n",
    "        cls = int(class_idx[i]) if class_idx is not None else -1\n",
    "        label = coco_names[cls] if (0 <= cls < len(coco_names)) else str(cls)\n",
    "        sc = float(final_score[i])\n",
    "        cv2.rectangle(vis, (xa, ya), (xb, yb), (0, 255, 0), 2)\n",
    "        cv2.putText(vis, f'{label} {sc:.2f}', (xa, max(ya - 6, 0)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,0), 2)\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(vis)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Detections array missing or not in expected format. See printed output shapes and adapt parsing as needed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e3d3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Apply Non-Maximum Suppression (NMS) and visualize filtered detections\n",
    "# This cell implements a small NMS utility with a Torch-based path (if available) and a numpy fallback.\n",
    "# It expects the variable `dets` to be present as in the previous inference cell, but it recomputes\n",
    "# scores and box coords to be self-contained for convenience.\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Numpy fallback NMS\n",
    "def nms_numpy(boxes, scores, iou_thr=0.45):\n",
    "    # boxes: (N,4) x1,y1,x2,y2\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    order = scores.argsort()[::-1]\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "        w = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "        inter = w * h\n",
    "        iou = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "        inds = np.where(iou <= iou_thr)[0]\n",
    "        order = order[inds + 1]\n",
    "    return np.array(keep, dtype=int)\n",
    "\n",
    "# Try Torch-based NMS if available\n",
    "def run_nms(boxes, scores, iou_thr=0.45):\n",
    "    try:\n",
    "        import torch\n",
    "        from torchvision.ops import nms as nms_torch\n",
    "        boxes_t = torch.tensor(boxes, dtype=torch.float32)\n",
    "        scores_t = torch.tensor(scores, dtype=torch.float32)\n",
    "        keep = nms_torch(boxes_t, scores_t, iou_thr).cpu().numpy()\n",
    "        return np.asarray(keep, dtype=int)\n",
    "    except Exception:\n",
    "        return nms_numpy(boxes, scores, iou_thr)\n",
    "\n",
    "# Ensure dets exists\n",
    "if 'dets' not in globals() or dets is None:\n",
    "    print('No detections available from the previous inference cell. Run the inference cell first.')\n",
    "else:\n",
    "    # Recompute box coordinates and scores (same logic as previous cell)\n",
    "    x = dets[:, 0]\n",
    "    y = dets[:, 1]\n",
    "    w = dets[:, 2]\n",
    "    h = dets[:, 3]\n",
    "    conf = dets[:, 4]\n",
    "\n",
    "    if dets.shape[1] > 6:\n",
    "        class_scores = dets[:, 5:]\n",
    "        class_idx = np.argmax(class_scores, axis=1)\n",
    "        class_score = np.max(class_scores, axis=1)\n",
    "        final_score = conf * class_score\n",
    "    else:\n",
    "        class_idx = dets[:, 5].astype(int)\n",
    "        final_score = conf\n",
    "\n",
    "    # If normalized coordinates, convert to input_size pixels\n",
    "    if np.max(w) <= 1.0 + 1e-6:\n",
    "        x *= input_size\n",
    "        y *= input_size\n",
    "        w *= input_size\n",
    "        h *= input_size\n",
    "\n",
    "    x1 = x - w / 2\n",
    "    y1 = y - h / 2\n",
    "    x2 = x + w / 2\n",
    "    y2 = y + h / 2\n",
    "\n",
    "    # Scale back to original image size\n",
    "    sx = orig_w / input_size\n",
    "    sy = orig_h / input_size\n",
    "    x1 *= sx; x2 *= sx; y1 *= sy; y2 *= sy\n",
    "\n",
    "    boxes = np.vstack([x1, y1, x2, y2]).T\n",
    "    scores = final_score\n",
    "\n",
    "    # Threshold first, then NMS\n",
    "    pre_keep = np.where(scores > conf_thresh)[0]\n",
    "    print(f'Before NMS: {len(pre_keep)} boxes pass score threshold ({conf_thresh})')\n",
    "    if pre_keep.size == 0:\n",
    "        print('No boxes to run NMS on after thresholding.')\n",
    "    else:\n",
    "        boxes_pre = boxes[pre_keep]\n",
    "        scores_pre = scores[pre_keep]\n",
    "        keep_inds = run_nms(boxes_pre, scores_pre, iou_thr=0.45)\n",
    "        final_inds = pre_keep[keep_inds]\n",
    "        print(f'After NMS: {len(final_inds)} boxes remain (IoU thr=0.45)')\n",
    "\n",
    "        vis_nms = img_rgb.copy()\n",
    "        for i in final_inds:\n",
    "            xa, ya, xb, yb = int(x1[i]), int(y1[i]), int(x2[i]), int(y2[i])\n",
    "            cls = int(class_idx[i]) if class_idx is not None else -1\n",
    "            label = coco_names[cls] if (0 <= cls < len(coco_names)) else str(cls)\n",
    "            sc = float(scores[i])\n",
    "            cv2.rectangle(vis_nms, (xa, ya), (xb, yb), (255, 0, 0), 2)  # blue for NMS results\n",
    "            cv2.putText(vis_nms, f'{label} {sc:.2f}', (xa, max(ya - 6, 0)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,0), 2)\n",
    "\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.axis('off')\n",
    "        plt.imshow(vis_nms)\n",
    "        plt.title('Detections after NMS')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0c3571",
   "metadata": {},
   "source": [
    "## Interactive: NMS & Threshold Tuner\n",
    "Use the sliders to adjust confidence (`conf_thresh`) and IoU (`iou_thr`) thresholds and see immediate results. Run the inference cell first to generate `dets`.\n",
    "\n",
    "This cell installs `ipywidgets` if necessary and creates interactive sliders that update the visualization and counts in-place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de03e51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NMS tuner with ipywidgets (extended: class filter)\n",
    "# Installs ipywidgets in Colab if missing and provides interactive sliders and a class selector.\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from ipywidgets import FloatSlider\n",
    "    from IPython.display import display, clear_output\n",
    "except Exception:\n",
    "    # Try to install in Colab\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install ipywidgets --quiet\n",
    "    import ipywidgets as widgets\n",
    "    from ipywidgets import FloatSlider\n",
    "    from IPython.display import display, clear_output\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def nms_numpy(boxes, scores, iou_thr=0.45):\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    order = scores.argsort()[::-1]\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "        w = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "        inter = w * h\n",
    "        iou = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "        inds = np.where(iou <= iou_thr)[0]\n",
    "        order = order[inds + 1]\n",
    "    return np.array(keep, dtype=int)\n",
    "\n",
    "\n",
    "def run_nms(boxes, scores, iou_thr=0.45):\n",
    "    try:\n",
    "        import torch\n",
    "        from torchvision.ops import nms as nms_torch\n",
    "        boxes_t = torch.tensor(boxes, dtype=torch.float32)\n",
    "        scores_t = torch.tensor(scores, dtype=torch.float32)\n",
    "        keep = nms_torch(boxes_t, scores_t, iou_thr).cpu().numpy()\n",
    "        return np.asarray(keep, dtype=int)\n",
    "    except Exception:\n",
    "        return nms_numpy(boxes, scores, iou_thr)\n",
    "\n",
    "\n",
    "def nms_tuner(conf_thresh=0.4, iou_thr=0.45, class_filter=('All',)):\n",
    "    \"\"\"Apply class filtering, score threshold, and NMS; display results interactively.\n",
    "\n",
    "    class_filter: tuple of selected class names; include 'All' to disable filtering.\n",
    "    \"\"\"\n",
    "    clear_output(wait=True)\n",
    "    print(f\"conf_thresh={conf_thresh:.2f}, iou_thr={iou_thr:.2f}, class_filter={class_filter}\")\n",
    "\n",
    "    if 'dets' not in globals() or dets is None:\n",
    "        print('No detections found. Run the inference cell first to populate `dets`.')\n",
    "        return\n",
    "\n",
    "    x = dets[:, 0]\n",
    "    y = dets[:, 1]\n",
    "    w = dets[:, 2]\n",
    "    h = dets[:, 3]\n",
    "    conf = dets[:, 4]\n",
    "\n",
    "    if dets.shape[1] > 6:\n",
    "        class_scores = dets[:, 5:]\n",
    "        class_idx = np.argmax(class_scores, axis=1)\n",
    "        class_score = np.max(class_scores, axis=1)\n",
    "        final_score = conf * class_score\n",
    "    else:\n",
    "        class_idx = dets[:, 5].astype(int)\n",
    "        final_score = conf\n",
    "\n",
    "    # If normalized coordinates, convert to input_size pixels\n",
    "    if np.max(w) <= 1.0 + 1e-6:\n",
    "        x *= input_size\n",
    "        y *= input_size\n",
    "        w *= input_size\n",
    "        h *= input_size\n",
    "\n",
    "    x1 = x - w / 2\n",
    "    y1 = y - h / 2\n",
    "    x2 = x + w / 2\n",
    "    y2 = y + h / 2\n",
    "\n",
    "    # Scale back to original image size\n",
    "    sx = orig_w / input_size\n",
    "    sy = orig_h / input_size\n",
    "    x1 *= sx; x2 *= sx; y1 *= sy; y2 *= sy\n",
    "\n",
    "    boxes = np.vstack([x1, y1, x2, y2]).T\n",
    "    scores = final_score\n",
    "\n",
    "    # Build class mask\n",
    "    if 'coco_names' in globals():\n",
    "        class_name_to_idx = {name: idx for idx, name in enumerate(coco_names)}\n",
    "        if 'All' in class_filter or len(class_filter) == 0:\n",
    "            class_mask = np.ones_like(scores, dtype=bool)\n",
    "        else:\n",
    "            allowed = [class_name_to_idx.get(c) for c in class_filter if c in class_name_to_idx]\n",
    "            if len(allowed) == 0:\n",
    "                print('No selected classes matched known class list; showing none.')\n",
    "                class_mask = np.zeros_like(scores, dtype=bool)\n",
    "            else:\n",
    "                class_mask = np.isin(class_idx, allowed)\n",
    "    else:\n",
    "        # If no class names metadata, accept all\n",
    "        class_mask = np.ones_like(scores, dtype=bool)\n",
    "\n",
    "    # Threshold + class filter\n",
    "    pre_keep = np.where((scores > conf_thresh) & class_mask)[0]\n",
    "    print(f'Before NMS: {len(pre_keep)} boxes pass score threshold & class filter')\n",
    "    if pre_keep.size == 0:\n",
    "        return\n",
    "\n",
    "    boxes_pre = boxes[pre_keep]\n",
    "    scores_pre = scores[pre_keep]\n",
    "    keep_inds = run_nms(boxes_pre, scores_pre, iou_thr)\n",
    "    final_inds = pre_keep[keep_inds]\n",
    "    print(f'After NMS: {len(final_inds)} boxes remain (IoU thr={iou_thr:.2f})')\n",
    "\n",
    "    vis = img_rgb.copy()\n",
    "    for i in final_inds:\n",
    "        xa, ya, xb, yb = int(x1[i]), int(y1[i]), int(x2[i]), int(y2[i])\n",
    "        cls = int(class_idx[i]) if class_idx is not None else -1\n",
    "        label = coco_names[cls] if (0 <= cls < len(coco_names)) else str(cls)\n",
    "        sc = float(scores[i])\n",
    "        cv2.rectangle(vis, (xa, ya), (xb, yb), (0, 0, 255), 2)  # red for tuned results\n",
    "        cv2.putText(vis, f'{label} {sc:.2f}', (xa, max(ya - 6, 0)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,0), 2)\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(vis)\n",
    "    plt.show()\n",
    "\n",
    "# Create sliders and class selector\n",
    "conf_slider = FloatSlider(min=0.0, max=1.0, step=0.01, value=0.4, description='conf')\n",
    "iou_slider = FloatSlider(min=0.0, max=1.0, step=0.01, value=0.45, description='iou')\n",
    "\n",
    "try:\n",
    "    classes_list = ['All'] + list(coco_names)\n",
    "except Exception:\n",
    "    classes_list = ['All']\n",
    "\n",
    "class_selector = widgets.SelectMultiple(options=classes_list, value=('All',), description='classes', rows=min(12, max(3, len(classes_list))))\n",
    "\n",
    "out = widgets.interactive_output(nms_tuner, {'conf_thresh': conf_slider, 'iou_thr': iou_slider, 'class_filter': class_selector})\n",
    "controls = widgets.VBox([widgets.HBox([conf_slider, iou_slider]), class_selector])\n",
    "display(controls, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7efbbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export filtered detections to CSV (button)\n",
    "# This cell adds a button that exports the currently filtered + NMS'd detections to a CSV file\n",
    "# and triggers a download in Colab if available.\n",
    "\n",
    "import csv\n",
    "import os\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "def compute_final_detections(conf_thresh, iou_thr, class_filter):\n",
    "    if 'dets' not in globals() or dets is None:\n",
    "        print('No detections available. Run the inference cell first.')\n",
    "        return []\n",
    "\n",
    "    x = dets[:, 0]\n",
    "    y = dets[:, 1]\n",
    "    w = dets[:, 2]\n",
    "    h = dets[:, 3]\n",
    "    conf = dets[:, 4]\n",
    "\n",
    "    if dets.shape[1] > 6:\n",
    "        class_scores = dets[:, 5:]\n",
    "        class_idx = np.argmax(class_scores, axis=1)\n",
    "        class_score = np.max(class_scores, axis=1)\n",
    "        final_score = conf * class_score\n",
    "    else:\n",
    "        class_idx = dets[:, 5].astype(int)\n",
    "        final_score = conf\n",
    "\n",
    "    # If normalized coordinates, convert to input_size pixels\n",
    "    if np.max(w) <= 1.0 + 1e-6:\n",
    "        x *= input_size\n",
    "        y *= input_size\n",
    "        w *= input_size\n",
    "        h *= input_size\n",
    "\n",
    "    x1 = x - w / 2\n",
    "    y1 = y - h / 2\n",
    "    x2 = x + w / 2\n",
    "    y2 = y + h / 2\n",
    "\n",
    "    # Scale back to original image size\n",
    "    sx = orig_w / input_size\n",
    "    sy = orig_h / input_size\n",
    "    x1 *= sx; x2 *= sx; y1 *= sy; y2 *= sy\n",
    "\n",
    "    boxes = np.vstack([x1, y1, x2, y2]).T\n",
    "    scores = final_score\n",
    "\n",
    "    # Build class mask\n",
    "    if 'coco_names' in globals():\n",
    "        class_name_to_idx = {name: idx for idx, name in enumerate(coco_names)}\n",
    "        if 'All' in class_filter or len(class_filter) == 0:\n",
    "            class_mask = np.ones_like(scores, dtype=bool)\n",
    "        else:\n",
    "            allowed = [class_name_to_idx.get(c) for c in class_filter if c in class_name_to_idx]\n",
    "            allowed = [a for a in allowed if a is not None]\n",
    "            if len(allowed) == 0:\n",
    "                class_mask = np.zeros_like(scores, dtype=bool)\n",
    "            else:\n",
    "                class_mask = np.isin(class_idx, allowed)\n",
    "    else:\n",
    "        class_mask = np.ones_like(scores, dtype=bool)\n",
    "\n",
    "    pre_keep = np.where((scores > conf_thresh) & class_mask)[0]\n",
    "    if pre_keep.size == 0:\n",
    "        return []\n",
    "\n",
    "    boxes_pre = boxes[pre_keep]\n",
    "    scores_pre = scores[pre_keep]\n",
    "\n",
    "    keep_inds = run_nms(boxes_pre, scores_pre, iou_thr)\n",
    "    final_inds = pre_keep[keep_inds]\n",
    "\n",
    "    results = []\n",
    "    for i in final_inds:\n",
    "        cls = int(class_idx[i]) if class_idx is not None else -1\n",
    "        label = coco_names[cls] if ('coco_names' in globals() and 0 <= cls < len(coco_names)) else str(cls)\n",
    "        results.append({\n",
    "            'x1': float(x1[i]), 'y1': float(y1[i]), 'x2': float(x2[i]), 'y2': float(y2[i]),\n",
    "            'score': float(scores[i]), 'class_idx': cls, 'class_name': label\n",
    "        })\n",
    "    return results\n",
    "\n",
    "\n",
    "# Button and handler\n",
    "out_label = widgets.Label(value='No export yet')\n",
    "export_button = widgets.Button(description='Export CSV', button_style='success')\n",
    "\n",
    "\n",
    "def on_export_clicked(b):\n",
    "    conf_val = conf_slider.value\n",
    "    iou_val = iou_slider.value\n",
    "    cls_val = tuple(class_selector.value)\n",
    "    dets_list = compute_final_detections(conf_val, iou_val, cls_val)\n",
    "    if len(dets_list) == 0:\n",
    "        out_label.value = 'No detections to export.'\n",
    "        return\n",
    "\n",
    "    fname = 'detections_export.csv'\n",
    "    keys = ['x1', 'y1', 'x2', 'y2', 'score', 'class_idx', 'class_name']\n",
    "    with open(fname, 'w', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=keys)\n",
    "        writer.writeheader()\n",
    "        for row in dets_list:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    # Try Colab download\n",
    "    try:\n",
    "        from google.colab import files as colab_files\n",
    "        colab_files.download(fname)\n",
    "        out_label.value = f'Exported {len(dets_list)} rows and triggered download.'\n",
    "    except Exception:\n",
    "        out_label.value = f'Exported {len(dets_list)} rows to {os.path.abspath(fname)}'\n",
    "\n",
    "export_button.on_click(on_export_clicked)\n",
    "\n",
    "# Display controls\n",
    "display(widgets.HBox([export_button, out_label]))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
